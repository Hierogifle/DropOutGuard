{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78cfd179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š PrÃ©paration du tÃ©lÃ©chargement des librairies...\n",
      "âœ… Librairies importÃ©es avec succÃ¨s !\n",
      "ğŸ“¥ TÃ©lÃ©chargement des datasets en cours...\n",
      "âœ… TÃ©lÃ©chargement des datasets terminÃ© !\n",
      "ğŸ’¾ Fichier bien enregistrÃ© dans : c:\\Users\\romua\\Documents\\La_Plateforme_\\Projet 5 - Perceptron Multicouche\\ANN-playground\\data\\data_brut.csv\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š TÃ‰LÃ‰CHARGEMENT DU DATASET\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Importation des librairies et tÃ©lÃ©chargement du dataset depuis UCI\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# _________________ 1ï¸âƒ£  IMPORTATION DES LIBRAIRIES _______________________\n",
    "# Import des librairies nÃ©cessaires\n",
    "\n",
    "print(\"ğŸ“š PrÃ©paration du tÃ©lÃ©chargement des librairies...\")\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"âœ… Librairies importÃ©es avec succÃ¨s !\")\n",
    "\n",
    "# _________________ 2ï¸âƒ£  TÃ‰LÃ‰CHARGEMENT DES DONNÃ‰ES _______________________\n",
    "# DÃ©finir le chemin du dossier et du fichier\n",
    "data_folder = Path.cwd().parent / 'data'\n",
    "\n",
    "print(\"ğŸ“¥ TÃ©lÃ©chargement des datasets en cours...\")\n",
    "\n",
    "# RÃ©cupÃ©ration directe depuis UCI\n",
    "dataset = fetch_ucirepo(id=697) \n",
    "X = dataset.data.features\n",
    "y = dataset.data.targets\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(\"âœ… TÃ©lÃ©chargement des datasets terminÃ© !\")\n",
    "\n",
    "file_path = data_folder / \"data_brut.csv\"\n",
    "\n",
    "# _________________ 3ï¸âƒ£  SAUVEGARDE DES DONNÃ‰ES _______________________\n",
    "# Sauvegarder dans un fichier CSV local\n",
    "df.to_csv(file_path, sep=';', index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"ğŸ’¾ Fichier bien enregistrÃ© dans : {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "371607da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ Infos sur le DataFrame :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4424 entries, 0 to 4423\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Marital Status                                  4424 non-null   int64  \n",
      " 1   Application mode                                4424 non-null   int64  \n",
      " 2   Application order                               4424 non-null   int64  \n",
      " 3   Course                                          4424 non-null   int64  \n",
      " 4   Daytime/evening attendance                      4424 non-null   int64  \n",
      " 5   Previous qualification                          4424 non-null   int64  \n",
      " 6   Previous qualification (grade)                  4424 non-null   float64\n",
      " 7   Nacionality                                     4424 non-null   int64  \n",
      " 8   Mother's qualification                          4424 non-null   int64  \n",
      " 9   Father's qualification                          4424 non-null   int64  \n",
      " 10  Mother's occupation                             4424 non-null   int64  \n",
      " 11  Father's occupation                             4424 non-null   int64  \n",
      " 12  Admission grade                                 4424 non-null   float64\n",
      " 13  Displaced                                       4424 non-null   int64  \n",
      " 14  Educational special needs                       4424 non-null   int64  \n",
      " 15  Debtor                                          4424 non-null   int64  \n",
      " 16  Tuition fees up to date                         4424 non-null   int64  \n",
      " 17  Gender                                          4424 non-null   int64  \n",
      " 18  Scholarship holder                              4424 non-null   int64  \n",
      " 19  Age at enrollment                               4424 non-null   int64  \n",
      " 20  International                                   4424 non-null   int64  \n",
      " 21  Curricular units 1st sem (credited)             4424 non-null   int64  \n",
      " 22  Curricular units 1st sem (enrolled)             4424 non-null   int64  \n",
      " 23  Curricular units 1st sem (evaluations)          4424 non-null   int64  \n",
      " 24  Curricular units 1st sem (approved)             4424 non-null   int64  \n",
      " 25  Curricular units 1st sem (grade)                4424 non-null   float64\n",
      " 26  Curricular units 1st sem (without evaluations)  4424 non-null   int64  \n",
      " 27  Curricular units 2nd sem (credited)             4424 non-null   int64  \n",
      " 28  Curricular units 2nd sem (enrolled)             4424 non-null   int64  \n",
      " 29  Curricular units 2nd sem (evaluations)          4424 non-null   int64  \n",
      " 30  Curricular units 2nd sem (approved)             4424 non-null   int64  \n",
      " 31  Curricular units 2nd sem (grade)                4424 non-null   float64\n",
      " 32  Curricular units 2nd sem (without evaluations)  4424 non-null   int64  \n",
      " 33  Unemployment rate                               4424 non-null   float64\n",
      " 34  Inflation rate                                  4424 non-null   float64\n",
      " 35  GDP                                             4424 non-null   float64\n",
      " 36  Target                                          4424 non-null   object \n",
      "dtypes: float64(7), int64(29), object(1)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "\n",
      "ğŸ‘» Valeurs manquantes par colonne :\n",
      "Marital Status                                    0\n",
      "Application mode                                  0\n",
      "Application order                                 0\n",
      "Course                                            0\n",
      "Daytime/evening attendance                        0\n",
      "Previous qualification                            0\n",
      "Previous qualification (grade)                    0\n",
      "Nacionality                                       0\n",
      "Mother's qualification                            0\n",
      "Father's qualification                            0\n",
      "Mother's occupation                               0\n",
      "Father's occupation                               0\n",
      "Admission grade                                   0\n",
      "Displaced                                         0\n",
      "Educational special needs                         0\n",
      "Debtor                                            0\n",
      "Tuition fees up to date                           0\n",
      "Gender                                            0\n",
      "Scholarship holder                                0\n",
      "Age at enrollment                                 0\n",
      "International                                     0\n",
      "Curricular units 1st sem (credited)               0\n",
      "Curricular units 1st sem (enrolled)               0\n",
      "Curricular units 1st sem (evaluations)            0\n",
      "Curricular units 1st sem (approved)               0\n",
      "Curricular units 1st sem (grade)                  0\n",
      "Curricular units 1st sem (without evaluations)    0\n",
      "Curricular units 2nd sem (credited)               0\n",
      "Curricular units 2nd sem (enrolled)               0\n",
      "Curricular units 2nd sem (evaluations)            0\n",
      "Curricular units 2nd sem (approved)               0\n",
      "Curricular units 2nd sem (grade)                  0\n",
      "Curricular units 2nd sem (without evaluations)    0\n",
      "Unemployment rate                                 0\n",
      "Inflation rate                                    0\n",
      "GDP                                               0\n",
      "Target                                            0\n",
      "dtype: int64\n",
      "\n",
      "â€¼ï¸ Nombre de doublons dans le DataFrame : 0\n",
      "\n",
      "Distribution des cibles dans le DataFrame modifiÃ© :\n",
      "Target\n",
      "Graduate    2209\n",
      "Dropout     1421\n",
      "Enrolled     794\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Pourcentages:\n",
      "Target\n",
      "Graduate    49.9\n",
      "Dropout     32.1\n",
      "Enrolled    17.9\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‹ INFORMATION SUR LE DATASET BRUT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Affichage des informations sur le dataset brut\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# _________________ 1ï¸âƒ£  CHARGEMENT DES DONNÃ‰ES _______________________\n",
    "# Recharger le fichier CSV pour s'assurer de partir d'une version propre\n",
    "file_path = data_folder / \"data_brut.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# _________________ 2ï¸âƒ£  AFFICHAGE DES INFORMATIONS _______________________\n",
    "# Affichage des informations gÃ©nÃ©rales sur le DataFrame\n",
    "print(\"\\nğŸ“‹ Infos sur le DataFrame :\")\n",
    "print(df.info())\n",
    "\n",
    "# VÃ©rification des valeurs manquantes dans chaque colonne\n",
    "print(\"\\nğŸ‘» Valeurs manquantes par colonne :\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Verification des doublons\n",
    "print(f\"\\nâ€¼ï¸ Nombre de doublons dans le DataFrame : {df.duplicated().sum()}\")\n",
    "\n",
    "# Afficher les informations sur les targets\n",
    "print(\"\\nDistribution des cibles dans le DataFrame modifiÃ© :\")\n",
    "print(df['Target'].value_counts())\n",
    "print(\"\\nPourcentages:\")\n",
    "print((df['Target'].value_counts(normalize=True) * 100).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d86630d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "â– Suppression des anomalies en cours...\n",
      "================================================================================\n",
      "\n",
      "Nombre de lignes supprimÃ© pour le code mÃ©tier spÃ©cifiÃ© : 28\n",
      "\n",
      "Pourcentage de lignes supprimÃ©es : 0.63%\n",
      "\n",
      "Nombre de lignes supprimÃ© pour le code de cours spÃ©cifiÃ© : 215\n",
      "\n",
      "Pourcentage de lignes supprimÃ©es : 4.89%\n",
      "\n",
      "================================================================================\n",
      "â• Ajout des nouvelles features en cours...\n",
      "=================================================================================\n",
      "\n",
      "Ajout des groupes de nationalitÃ©s...\n",
      "\n",
      "Ajout des groupes de qualifications des parents...\n",
      "\n",
      "Ajout des groupes de profession des parents...\n",
      "\n",
      "Ajout du rapport entre matiÃ¨res inscrites et validÃ©es...\n",
      "\n",
      "Ajout des Features terminÃ©.\n",
      "\n",
      "Suppression des features remplacÃ©es...\n",
      "\n",
      "Suppression des features terminÃ©e.\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ STANDARDISATION DES DONNEES NUMERIQUES...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¾ Affichage des modifications et enregistrement du DataFrame modifiÃ©...\n",
      "================================================================================\n",
      "\n",
      "ğŸ›ï¸ Information sur les colonnes modifiÃ©es :\n",
      "Nombre de colonnes supprimÃ©es : 6\n",
      "Pourcentage de colonnes supprimÃ©es  : 16.67%\n",
      "Nombre de colonnes ajoutÃ©es : 8\n",
      "Pourcentage de colonnes ajoutÃ©es  : 26.67%\n",
      "\n",
      "ã€°ï¸ Information sur les lignes modifiÃ©es :\n",
      "Nombre de lignes supprimÃ© au totale : 243\n",
      "Pourcentage de lignes supprimÃ©es : 5.49%\n",
      "\n",
      "ğŸ–¼ï¸ Information sur le DataFrame modifiÃ© :\n",
      "- Nombre de lignes : 4181\n",
      "- Nombre de colonnes : 39\n",
      "\n",
      "ğŸ¯ Information sur la rÃ©partition des targets :\n",
      "Distribution des cibles dans le DataFrame modifiÃ© :\n",
      "Target\n",
      "1    2097\n",
      "0    1339\n",
      "2     745\n",
      "Name: count, dtype: int64\n",
      "Pourcentages:\n",
      "Target\n",
      "1    50.2\n",
      "0    32.0\n",
      "2    17.8\n",
      "Name: proportion, dtype: float64\n",
      "DiffÃ©rence de rÃ©partition des cibles avant et aprÃ¨s modification :\n",
      "Target\n",
      "0          NaN\n",
      "1          NaN\n",
      "2          NaN\n",
      "Dropout    NaN\n",
      "Enrolled   NaN\n",
      "Graduate   NaN\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "ğŸ’¾ Fichier modifiÃ© bien enregistrÃ© dans : c:\\Users\\romua\\Documents\\La_Plateforme_\\Projet 5 - Perceptron Multicouche\\ANN-playground\\data\\data_update.csv\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‹ MODIFICATION DU DATASET\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Suppression des anomalies et ajout de nouvelles features\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# _________________ 1ï¸âƒ£  CHARGEMENT DES DONNÃ‰ES _______________________\n",
    "# Recharger le fichier CSV pour s'assurer de partir d'une version propre\n",
    "\n",
    "# DÃ©finir le chemin du dossier et du fichier\n",
    "file_path = data_folder / \"data_brut.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# â– SUPPRESSION DES ANOMALIES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Suppression des anomalies\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"â– Suppression des anomalies en cours...\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# _________________ 2ï¸âƒ£  DEFINITION DES CODES A SUPPRIMER _______________________\n",
    "# Suppression des lignes oÃ¹ \"Mother's occupation\"/\"Father's occupation\" est 125, 173 et 191 et \"Course code\" est 171\n",
    "\n",
    "# Codes Ã  supprimer\n",
    "codes_to_remove = [125, 173, 191]\n",
    "codes_course_to_remove = [171]\n",
    "\n",
    "# Nombre de lignes avant suppression\n",
    "n_before = len(df)\n",
    "\n",
    "# _________________ 3ï¸âƒ£  SUPPRESSION DES OCCUPATIONS ANORMALES _______________________\n",
    "# Suppression des lignes\n",
    "df = df[~df[\"Mother's occupation\"].isin(codes_to_remove)].copy()\n",
    "df = df[~df[\"Father's occupation\"].isin(codes_to_remove)].copy()\n",
    "n_after_occupation_remove = len(df)\n",
    "\n",
    "# Nombre de lignes aprÃ¨s suppression\n",
    "n_removed_occupation = n_before - n_after_occupation_remove\n",
    "\n",
    "# _________________ 4ï¸âƒ£  SUPPRESSION DES COURSES ANORMALES _______________________\n",
    "# Suppression des lignes pour le code de cours spÃ©cifiÃ©\n",
    "df = df[~df[\"Course\"].isin(codes_course_to_remove)].copy()\n",
    "n_after_course_remove = len(df)\n",
    "\n",
    "# Nombre de lignes supprimÃ©es pour le code de cours spÃ©cifiÃ©\n",
    "n_removed_course = n_after_occupation_remove - n_after_course_remove\n",
    "\n",
    "# _________________ 5ï¸âƒ£  AFFICHAGE DES RÃ‰SULTATS _______________________\n",
    "# Nombre totale de lignes supprimÃ©es\n",
    "n_removed = n_removed_course+n_removed_occupation\n",
    "\n",
    "print(f\"\\nNombre de lignes supprimÃ© pour le code mÃ©tier spÃ©cifiÃ© : {n_removed_occupation}\")\n",
    "print(f\"\\nPourcentage de lignes supprimÃ©es : {(n_removed_occupation / n_before) * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nNombre de lignes supprimÃ© pour le code de cours spÃ©cifiÃ© : {n_removed_course}\")\n",
    "print(f\"\\nPourcentage de lignes supprimÃ©es : {(n_removed_course / n_after_occupation_remove ) * 100:.2f}%\")\n",
    "\n",
    "# â• AJOUT DE FEATURES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Ajout de nouvelles features basÃ©es sur les colonnes existantes\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"â• Ajout des nouvelles features en cours...\")\n",
    "print(f\"={'='*80}\")\n",
    "\n",
    "# _________________ 6ï¸âƒ£  AJOUT DES GROUPES DE QUALIFICATIONS _______________________\n",
    "# Dictionnaire des groupes de qualifications\n",
    "\n",
    "qualification_groups = {\n",
    "    0: {\n",
    "        4 : 'DiplÃ´me supÃ©rieur de troisiÃ¨me cycle (Doctorat)',\n",
    "        43 : 'Enseignement supÃ©rieur - doctorat (3áµ‰ cycle)',\n",
    "        3 : 'DiplÃ´me supÃ©rieur de deuxiÃ¨me cycle (Master)',\n",
    "        2 : 'DiplÃ´me supÃ©rieur de premier cycle (Licence/Bachelor)',\n",
    "        40 : 'DiplÃ´me de premier cycle universitaire',\n",
    "        6 : 'Autres formations supÃ©rieures'\n",
    "    },\n",
    "    1: {\n",
    "        42 : 'DiplÃ´me technique professionnel supÃ©rieur',\n",
    "        39 : 'DiplÃ´me de spÃ©cialisation technologique',\n",
    "        5 : 'Formation professionnelle continue'\n",
    "    },\n",
    "    2: {\n",
    "        1 : 'Enseignement secondaire',\n",
    "        9 : \"12áµ‰ annÃ©e d'Ã©tudes non complÃ©tÃ©e\",\n",
    "        10 : \"11áµ‰ annÃ©e d'Ã©tudes non complÃ©tÃ©e\",\n",
    "        12 : 'Autres formations de 11áµ‰ annÃ©e',\n",
    "        14 : '10áµ‰ annÃ©e',\n",
    "        15 : '10áµ‰ annÃ©e non complÃ©tÃ©e'\n",
    "    },\n",
    "    3: {\n",
    "        19 : 'Ã‰ducation de base 3áµ‰ cycle (9áµ‰/10áµ‰/11áµ‰ annÃ©e)',\n",
    "        38 : 'Ã‰ducation de base 2áµ‰ cycle (6áµ‰/7áµ‰/8áµ‰ annÃ©e)'\n",
    "    }\n",
    "}\n",
    "\n",
    "def map_qualification_group(code):\n",
    "    try:\n",
    "        code = int(code)\n",
    "    except:\n",
    "        return None\n",
    "    for group, codes in qualification_groups.items():\n",
    "        if code in codes:\n",
    "            return group\n",
    "    return None\n",
    "\n",
    "df['Previous qualification Group'] = df['Previous qualification'].apply(map_qualification_group)\n",
    "\n",
    "# RÃ©organiser les colonnes pour insÃ©rer la nouvelle juste aprÃ¨s \"Previous qualification\"\n",
    "cols = list(df.columns)\n",
    "idx = cols.index('Previous qualification')\n",
    "cols.insert(idx+1, cols.pop(cols.index('Previous qualification Group')))\n",
    "df = df[cols]\n",
    "\n",
    "# _________________ 7ï¸âƒ£  AJOUT DES GROUPES DE NATIONALITÃ‰S _______________________\n",
    "\n",
    "print(\"\\nAjout des groupes de nationalitÃ©s...\")\n",
    "\n",
    "# Dictionnaire de classification des groupes de nationalitÃ©s\n",
    "nationality_groups = {\n",
    "    0: {\n",
    "        2: 'Elite EuropÃ©enne Occidentale',\n",
    "        13: 'Elite EuropÃ©enne Occidentale',\n",
    "        14: 'Elite EuropÃ©enne Occidentale',\n",
    "        1: 'Europe du Sud DÃ©veloppÃ©e',\n",
    "        6: 'Europe du Sud DÃ©veloppÃ©e',\n",
    "        11: 'Europe du Sud DÃ©veloppÃ©e',\n",
    "    },\n",
    "    1: {\n",
    "        17: 'Europe de l Est IntÃ©grÃ©e',\n",
    "        62: 'Europe de l Est IntÃ©grÃ©e',\n",
    "        32: 'Puissances Ã‰mergentes',\n",
    "        105: 'Puissances Ã‰mergentes',\n",
    "    },\n",
    "    2: {\n",
    "        41: 'AmÃ©rique Latine Ã‰mergente',\n",
    "        101: 'AmÃ©rique Latine Ã‰mergente',\n",
    "        109: 'AmÃ©rique Latine Ã‰mergente',\n",
    "        100: 'Europe de l Est en Transition',\n",
    "        103: 'Europe de l Est en Transition',\n",
    "        108: 'SystÃ¨mes Autoritaires SpÃ©cifiques',\n",
    "    },\n",
    "    4: {\n",
    "        22: 'Ãles Atlantiques StabilisÃ©es',\n",
    "        26: 'Ãles Atlantiques StabilisÃ©es',\n",
    "        21: 'GÃ©ants Africains Ressources Naturelles',\n",
    "        25: 'GÃ©ants Africains Ressources Naturelles',\n",
    "        24: 'Petits Ã‰tats Fragiles',\n",
    "    }\n",
    "}\n",
    "\n",
    "# Fonction pour mapper le code nationalitÃ© vers le groupe\n",
    "def map_nationality_group(code):\n",
    "    try:\n",
    "        code = int(code)\n",
    "    except:\n",
    "        return None\n",
    "    for group, codes in nationality_groups.items():\n",
    "        if code in codes:\n",
    "            return group\n",
    "    return None\n",
    "\n",
    "# Appliquer la fonction sur la colonne 'Nacionality'\n",
    "df['Nationality Group'] = df['Nacionality'].apply(map_nationality_group)\n",
    "\n",
    "# InsÃ©rer la nouvelle colonne juste aprÃ¨s 'Nacionality'\n",
    "cols = list(df.columns)\n",
    "idx = cols.index('Nacionality')\n",
    "cols.insert(idx + 1, cols.pop(cols.index('Nationality Group')))\n",
    "df = df[cols]\n",
    "\n",
    "# _________________ 8ï¸âƒ£  AJOUT DES GROUPES DE QUALIFICATIONS DES PARENTS _______________________\n",
    "\n",
    "print(\"\\nAjout des groupes de qualifications des parents...\")\n",
    "\n",
    "# Dictionnaire de classification des groupes de qualification parents\n",
    "parents_education_groups = {\n",
    "    0: {\n",
    "        5: \"Doctorat (3áµ‰ cycle)\",\n",
    "        44: \"Enseignement supÃ©rieur - doctorat (3áµ‰ cycle)\",\n",
    "        4: \"Master (2áµ‰ cycle)\",\n",
    "        43: \"Enseignement supÃ©rieur - master (2áµ‰ cycle)\",\n",
    "        3: \"DiplÃ´me supÃ©rieur deuxiÃ¨me cycle\",\n",
    "        41: \"Cours d'Ã©tudes supÃ©rieures spÃ©cialisÃ©es\",\n",
    "        40: \"Enseignement supÃ©rieur - diplÃ´me (1er cycle)\",\n",
    "        2: \"DiplÃ´me supÃ©rieur premier cycle\"\n",
    "    },\n",
    "    1: {\n",
    "        1: \"Enseignement secondaire (12áµ‰ annÃ©e ou Ã©quivalent)\",\n",
    "        9: \"12áµ‰ annÃ©e non complÃ©tÃ©e\",\n",
    "        10: \"11áµ‰ annÃ©e non complÃ©tÃ©e\",\n",
    "        12: \"Autres formations 11áµ‰ annÃ©e\",\n",
    "        13: \"2áµ‰ annÃ©e complÃ©mentaire lycÃ©e\",\n",
    "        14: \"10áµ‰ annÃ©e\",\n",
    "        20: \"Formation complÃ©mentaire lycÃ©e\",\n",
    "        22: \"Formation technique professionnelle\",\n",
    "        27: \"2áµ‰ cycle du lycÃ©e gÃ©nÃ©ral\",\n",
    "        39: \"Cursus de spÃ©cialisation technologique\",\n",
    "        42: \"Cours technique supÃ©rieur professionnel\"\n",
    "    },\n",
    "    2: {\n",
    "        19: \"Ã‰ducation de base 3áµ‰ cycle\",\n",
    "        25: \"Formation complÃ©mentaire non complÃ©tÃ©e\",\n",
    "        26: \"7áµ‰ annÃ©e\",\n",
    "        29: \"9áµ‰ annÃ©e non complÃ©tÃ©e\",\n",
    "        30: \"8áµ‰ annÃ©e\",\n",
    "        31: \"Cours gÃ©nÃ©raux administration et commerce\",\n",
    "        33: \"ComptabilitÃ© et administration\",\n",
    "        37: \"Ã‰ducation de base 1er cycle\",\n",
    "        38: \"Ã‰ducation de base 2áµ‰ cycle\",\n",
    "        18: \"Commerce gÃ©nÃ©ral\",\n",
    "        6: \"Formation continue\"\n",
    "    },\n",
    "    3: {\n",
    "        11: \"7áµ‰ annÃ©e (ancienne Ã©chelle)\",\n",
    "        34: \"Inconnu\",\n",
    "        35: \"AnalphabÃ¨te\",\n",
    "        36: \"Lecture sans formation complÃ¨te\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Fonction pour mapper le code nationalitÃ© vers le groupe\n",
    "def map_parents_education_group(code):\n",
    "    try:\n",
    "        code = int(code)\n",
    "    except:\n",
    "        return None\n",
    "    for group, codes in parents_education_groups.items():\n",
    "        if code in codes:\n",
    "            return group\n",
    "    return None\n",
    "\n",
    "# Appliquer la fonction sur la colonne 'Mothers qualification' et 'Fathers qualification'\n",
    "df[\"Mother's qualification Group\"] = df[\"Mother's qualification\"].apply(map_parents_education_group)\n",
    "df[\"Father's qualification Group\"] = df[\"Father's qualification\"].apply(map_parents_education_group)\n",
    "\n",
    "# InsÃ©rer la nouvelle colonne juste aprÃ¨s 'Mother's qualification'\n",
    "cols = list(df.columns)\n",
    "idx = cols.index(\"Mother's qualification\")\n",
    "cols.insert(idx + 1, cols.pop(cols.index(\"Mother's qualification Group\")))\n",
    "df = df[cols]\n",
    "\n",
    "# InsÃ©rer la nouvelle colonne juste aprÃ¨s 'Father's qualification'\n",
    "cols = list(df.columns)\n",
    "idx = cols.index(\"Father's qualification\")\n",
    "cols.insert(idx + 1, cols.pop(cols.index(\"Father's qualification Group\")))\n",
    "df = df[cols]\n",
    "\n",
    "# _________________ 9ï¸âƒ£  AJOUT DES GROUPES DE PROFESSION DES PARENTS _______________________\n",
    "\n",
    "print(\"\\nAjout des groupes de profession des parents...\")\n",
    "\n",
    "# Dictionnaire de classification des groupes de profession des parents\n",
    "parents_occupation_groups = {\n",
    "    0: {\n",
    "        1: \"ReprÃ©sentants du pouvoir lÃ©gislatif, directeurs et cadres dirigeants\",\n",
    "        2: \"SpÃ©cialistes des activitÃ©s intellectuelles et scientifiques\",\n",
    "        101: \"Officiers des forces armÃ©es\",\n",
    "        121: \"SpÃ©cialistes des sciences physiques, mathÃ©matiques, ingÃ©nierie\",\n",
    "        122: \"Professionnels de la santÃ©\",\n",
    "        123: \"Enseignants\",\n",
    "        124: \"SpÃ©cialistes en finance, comptabilitÃ©, organisation, relations publiques\"\n",
    "    },\n",
    "    1: {\n",
    "        3: \"Techniciens et professions de niveau intermÃ©diaire\",\n",
    "        102: \"Sous-officiers des forces armÃ©es\",\n",
    "        112: \"Directeurs des services administratifs et commerciaux\",\n",
    "        114: \"Directeurs de l'hÃ´tellerie, restauration, commerce et services\",\n",
    "        131: \"Techniciens et professions intermÃ©diaires des sciences et ingÃ©nierie\",\n",
    "        132: \"Techniciens et professionnels de santÃ© de niveau intermÃ©diaire\",\n",
    "        134: \"Techniciens intermÃ©diaires services juridiques, sociaux, sportifs, culturels\",\n",
    "        135: \"Techniciens en technologies de l'information et de la communication\"\n",
    "    },\n",
    "    2: {\n",
    "        4: \"Personnel administratif\",\n",
    "        103: \"Autre personnel des forces armÃ©es\",\n",
    "        141: \"EmployÃ©s de bureau, secrÃ©taires, opÃ©rateurs de saisie\",\n",
    "        143: \"OpÃ©rateurs de services de donnÃ©es, comptabilitÃ©, statistiques\",\n",
    "        144: \"Personnel de soutien administratif\",\n",
    "        154: \"Personnel des services de protection et de sÃ©curitÃ©\",\n",
    "        174: \"Ouvriers qualifiÃ©s en Ã©lectricitÃ© et Ã©lectronique\"\n",
    "    },\n",
    "    3: {\n",
    "        5: \"Travailleurs des services personnels, sÃ©curitÃ© et ventes\",\n",
    "        151: \"Travailleurs des services personnels\",\n",
    "        152: \"Vendeurs\",\n",
    "        153: \"Travailleurs des soins personnels et assimilÃ©s\",\n",
    "        161: \"Agriculteurs et ouvriers qualifiÃ©s de la production agricole et animale\",\n",
    "        171: \"Ouvriers qualifiÃ©s du bÃ¢timent et assimilÃ©s (sauf Ã©lectriciens)\",\n",
    "        172: \"Ouvriers qualifiÃ©s mÃ©tallurgie, travail des mÃ©taux\",\n",
    "        175: \"Travailleurs transformation alimentaire, bois, habillement, artisanats\",\n",
    "        181: \"OpÃ©rateurs d'installations fixes et machines\",\n",
    "        182: \"Travailleurs de l'assemblage\",\n",
    "        183: \"Conducteurs de vÃ©hicules et opÃ©rateurs d'Ã©quipements mobiles\"\n",
    "    },\n",
    "    4: {\n",
    "        6: \"Agriculteurs et ouvriers qualifiÃ©s agriculture, pÃªche et sylviculture\",\n",
    "        7: \"Ouvriers qualifiÃ©s industrie, construction et artisans\",\n",
    "        8: \"OpÃ©rateurs d'installation, machines et travailleurs de l'assemblage\",\n",
    "        163: \"Agriculteurs, Ã©leveurs, pÃªcheurs, chasseurs de subsistance\",\n",
    "        192: \"Travailleurs non qualifiÃ©s agriculture, production animale, pÃªche\",\n",
    "        193: \"Travailleurs non qualifiÃ©s industrie extractive, construction, fabrication\",\n",
    "        194: \"Aides Ã  la prÃ©paration des repas\",\n",
    "        195: \"Vendeurs ambulants (hors produits alimentaires) et prestataires de rue\"\n",
    "    },\n",
    "    5: {\n",
    "        9: \"Travailleurs non qualifiÃ©s\"\n",
    "    },\n",
    "    6: {\n",
    "        0: \"Ã‰tudiant (en formation)\",\n",
    "        10: \"Professions des forces armÃ©es (hiÃ©rarchie variable)\",\n",
    "        90: \"Autre situation\",\n",
    "        99: \"(vide)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Fonction pour mapper le code nationalitÃ© vers le groupe\n",
    "def map_parents_occupation_group(code):\n",
    "    try:\n",
    "        code = int(code)\n",
    "    except:\n",
    "        return None\n",
    "    for group, codes in parents_occupation_groups.items():\n",
    "        if code in codes:\n",
    "            return group\n",
    "    return None\n",
    "\n",
    "# Appliquer la fonction sur la colonne 'Mother's occupation' et 'Father's occupation'\n",
    "df[\"Mother's occupation Group\"] = df[\"Mother's occupation\"].apply(map_parents_occupation_group)\n",
    "df[\"Father's occupation Group\"] = df[\"Father's occupation\"].apply(map_parents_occupation_group)\n",
    "\n",
    "# InsÃ©rer la nouvelle colonne juste aprÃ¨s 'Mother's qualification'\n",
    "cols = list(df.columns)\n",
    "idx = cols.index(\"Mother's occupation\")\n",
    "cols.insert(idx + 1, cols.pop(cols.index(\"Mother's occupation Group\")))\n",
    "df = df[cols]\n",
    "\n",
    "# InsÃ©rer la nouvelle colonne juste aprÃ¨s 'Father's qualification'\n",
    "cols = list(df.columns)\n",
    "idx = cols.index(\"Father's occupation\")\n",
    "cols.insert(idx + 1, cols.pop(cols.index(\"Father's occupation Group\")))\n",
    "df = df[cols]\n",
    "\n",
    "\n",
    "# _________________ 1ï¸âƒ£0ï¸âƒ£  AJOUT DU RAPPORT ENTRE MATIÃˆRES INSCRITES ET VALIDÃ‰ES _______________________\n",
    "\n",
    "print(\"\\nAjout du rapport entre matiÃ¨res inscrites et validÃ©es...\")\n",
    "\n",
    "# Calculer le ratio et crÃ©er les nouvelles colonnes\n",
    "df[\"Curricular units 1st sem (Approved/Enrolled)\"] = df[\"Curricular units 1st sem (approved)\"] / df[\"Curricular units 1st sem (enrolled)\"]\n",
    "df[\"Curricular units 2nd sem (Approved/Enrolled)\"] = df[\"Curricular units 2nd sem (approved)\"] / df[\"Curricular units 2nd sem (enrolled)\"]\n",
    "\n",
    "# InsÃ©rer la nouvelle colonne juste aprÃ¨s 'Curricular units 1st sem (without evaluations)'\n",
    "cols = list(df.columns)\n",
    "idx = cols.index(\"Curricular units 1st sem (without evaluations)\")\n",
    "cols.insert(idx + 1, cols.pop(cols.index(\"Curricular units 1st sem (Approved/Enrolled)\")))\n",
    "df = df[cols]\n",
    "\n",
    "# InsÃ©rer la nouvelle colonne juste aprÃ¨s 'Curricular units 2nd sem (without evaluations)'\n",
    "cols = list(df.columns)\n",
    "idx = cols.index(\"Curricular units 2nd sem (without evaluations)\")\n",
    "cols.insert(idx + 1, cols.pop(cols.index(\"Curricular units 2nd sem (Approved/Enrolled)\")))\n",
    "df = df[cols]\n",
    "\n",
    "print(\"\\nAjout des Features terminÃ©.\")\n",
    "\n",
    "# _________________ 1ï¸âƒ£1ï¸âƒ£  SUPPRESSION DES FEATURES REMPLACÃ‰ES _______________________\n",
    "\n",
    "print(\"\\nSuppression des features remplacÃ©es...\")\n",
    "\n",
    "# Liste des colonnes Ã  supprimer\n",
    "columns_to_drop = [\n",
    "    'Nacionality',\n",
    "    'Previous qualification',\n",
    "    \"Mother's qualification\",\n",
    "    \"Father's qualification\",\n",
    "    \"Mother's occupation\",\n",
    "    \"Father's occupation\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"\\nSuppression des features terminÃ©e.\")\n",
    "\n",
    "# ğŸ’¾ STANDARDISATION DES VARIABLES NUMERIQUES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Standardisation des variables numÃ©riques\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# _________________ 1ï¸âƒ£2ï¸âƒ£  STANDARDISATION DES DONNEES NUMERIQUES _______________________\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ğŸ“ STANDARDISATION DES DONNEES NUMERIQUES...\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# colonnes numÃ©riques Ã  standardiser\n",
    "colonnes_a_scaler = [\n",
    "    \"Application order\", \"Previous qualification Group\" ,\"Previous qualification (grade)\", \"Nationality Group\", \n",
    "    \"Mother's qualification Group\", \"Father's qualification Group\", \"Mother's occupation Group\", \"Father's occupation Group\",\n",
    "    \"Admission grade\", \"Age at enrollment\", \"Curricular units 1st sem (credited)\", \n",
    "    \"Curricular units 1st sem (enrolled)\", \"Curricular units 1st sem (evaluations)\",\n",
    "    \"Curricular units 1st sem (approved)\", \"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\", \"Curricular units 1st sem (Approved/Enrolled)\",\n",
    "    \"Curricular units 2nd sem (credited)\", \"Curricular units 2nd sem (enrolled)\",\n",
    "    \"Curricular units 2nd sem (evaluations)\", \"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 2nd sem (grade)\", \"Curricular units 2nd sem (without evaluations)\",\n",
    "    \"Curricular units 2nd sem (Approved/Enrolled)\",\n",
    "    \"Unemployment rate\", \"Inflation rate\", \"GDP\"\n",
    "]\n",
    "\n",
    "# Garder l'ordre original des colonnes\n",
    "# ordre_original = df.columns.tolist()\n",
    "\n",
    "# CrÃ©er des copies des DataFrames pour le traitement\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Filtrer pour garder seulement les colonnes qui existent vraiment\n",
    "colonnes_a_scaler_existantes = [col for col in colonnes_a_scaler if col in df_processed.columns]\n",
    "\n",
    "# CrÃ©er le StandardScaler et l'entraÃ®ner sur le TRAIN\n",
    "scaler = StandardScaler()\n",
    "df_processed[colonnes_a_scaler_existantes] = scaler.fit_transform(df_processed[colonnes_a_scaler_existantes])\n",
    "df_processed[colonnes_a_scaler_existantes] = scaler.transform(df_processed[colonnes_a_scaler_existantes])\n",
    "\n",
    "# RÃ©organiser les colonnes pour correspondre Ã  l'ordre original\n",
    "# df_processed = df_processed[ordre_original]\n",
    "\n",
    "# Mettre Ã  jour le DataFrame original\n",
    "df = df_processed\n",
    "\n",
    "# ğŸ’¾ ENCODAGE TARGET\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Encodage de la variable cible\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Encodage de la variable cible 'Target'\n",
    "df['Target'] = df['Target'].map({'Dropout': 0, 'Graduate': 1, 'Enrolled': 2})\n",
    "\n",
    "# ğŸ’¾ AFFICHAGE DES MODIFICATIONS ET ENREGISTREMENT DU DATAFRAME MODIFIÃ‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Affichage des modifications et enregistrement du DataFrame modifiÃ©\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ğŸ’¾ Affichage des modifications et enregistrement du DataFrame modifiÃ©...\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# _________________ 1ï¸âƒ£3ï¸âƒ£  AFFICHAGE DES MODIFICATIONS _______________________\n",
    "# ğŸ“‹ RÃ‰SUMÃ‰ DES MODIFICATIONS\n",
    "\n",
    "# Nombre de colonnes supprimÃ©es\n",
    "print(\"\\nğŸ›ï¸ Information sur les colonnes modifiÃ©es :\")\n",
    "print(f\"Nombre de colonnes supprimÃ©es : {len(columns_to_drop)}\")\n",
    "print(f\"Pourcentage de colonnes supprimÃ©es  : {len(columns_to_drop)/36 * 100:.2f}%\")\n",
    "\n",
    "# Nombre de nouvelles colonnes ajoutÃ©es\n",
    "n_new_columns = 8  # 3 groupes de qualifications + 3 groupes de nationalitÃ©s + 2 ratios\n",
    "print(f\"Nombre de colonnes ajoutÃ©es : {n_new_columns}\")\n",
    "print(f\"Pourcentage de colonnes ajoutÃ©es  : {n_new_columns/ (36 - len(columns_to_drop)) * 100:.2f}%\")\n",
    "\n",
    "# Nombre totale de lignes supprimÃ©es\n",
    "print(\"\\nã€°ï¸ Information sur les lignes modifiÃ©es :\")\n",
    "print(f\"Nombre de lignes supprimÃ© au totale : {n_removed}\")\n",
    "print(f\"Pourcentage de lignes supprimÃ©es : {(n_removed / n_before) * 100:.2f}%\")\n",
    "\n",
    "# Informations sur le DataFrame modifiÃ©\n",
    "print(\"\\nğŸ–¼ï¸ Information sur le DataFrame modifiÃ© :\")\n",
    "print(f\"- Nombre de lignes : {df.shape[0]}\")\n",
    "print(f\"- Nombre de colonnes : {df.shape[1]}\")\n",
    "\n",
    "# Afficher les informations sur les targets\n",
    "print(\"\\nğŸ¯ Information sur la rÃ©partition des targets :\")\n",
    "print(\"Distribution des cibles dans le DataFrame modifiÃ© :\")\n",
    "print(df['Target'].value_counts())\n",
    "print(\"Pourcentages:\")\n",
    "print((df['Target'].value_counts(normalize=True) * 100).round(1))\n",
    "\n",
    "# DiffÃ©rence de rÃ©partition des cibles avant et aprÃ¨s modification\n",
    "print(\"DiffÃ©rence de rÃ©partition des cibles avant et aprÃ¨s modification :\")\n",
    "original_counts = pd.read_csv(data_folder / \"data_brut.csv\", sep=';')['Target'].value_counts(normalize=True) * 100\n",
    "modified_counts = df['Target'].value_counts(normalize=True) * 100\n",
    "difference = (modified_counts - original_counts).round(1)\n",
    "print(difference)\n",
    "\n",
    "\n",
    "# _________________ 1ï¸âƒ£4ï¸âƒ£  ENREGISTREMENT DU DATAFRAME MODIFIÃ‰ _______________________\n",
    "# DÃ©finir le chemin du dossier et du fichier\n",
    "file_path = data_folder / \"data_update.csv\"\n",
    "\n",
    "# Sauvegarder le DataFrame modifiÃ©\n",
    "df.to_csv(file_path, sep=';', index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nğŸ’¾ Fichier modifiÃ© bien enregistrÃ© dans : {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f0bf679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ—‘ï¸ SUPPRESSION DES FEATURES CORELLES...\n",
      "================================================================================\n",
      "\n",
      "Colonnes supprimÃ©es en raison de la corrÃ©lation Ã©levÃ©e : ['Curricular units 2nd sem (credited)', 'Curricular units 2nd sem (enrolled)', 'Curricular units 2nd sem (approved)', 'Curricular units 2nd sem (grade)', 'Curricular units 1st sem (approved)', 'Curricular units 1st sem (enrolled)', 'Curricular units 1st sem (credited)', 'Curricular units 1st sem (grade)', 'International']\n",
      "\n",
      "Nombre de colonnes restantes aprÃ¨s suppression : 30\n",
      "\n",
      "ğŸ–¼ï¸ Information sur le DataFrame aprÃ¨s suppression des colonnes corrÃ©lÃ©es :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4181 entries, 0 to 4180\n",
      "Data columns (total 30 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Marital Status                                  4181 non-null   object \n",
      " 1   Application mode                                4181 non-null   object \n",
      " 2   Application order                               4181 non-null   object \n",
      " 3   Course                                          4181 non-null   object \n",
      " 4   Daytime/evening attendance                      4181 non-null   object \n",
      " 5   Previous qualification Group                    4181 non-null   object \n",
      " 6   Previous qualification (grade)                  4181 non-null   object \n",
      " 7   Nationality Group                               4181 non-null   object \n",
      " 8   Mother's qualification Group                    4181 non-null   object \n",
      " 9   Father's qualification Group                    4181 non-null   object \n",
      " 10  Mother's occupation Group                       4181 non-null   object \n",
      " 11  Father's occupation Group                       4181 non-null   object \n",
      " 12  Admission grade                                 4181 non-null   object \n",
      " 13  Displaced                                       4181 non-null   object \n",
      " 14  Educational special needs                       4181 non-null   object \n",
      " 15  Debtor                                          4181 non-null   object \n",
      " 16  Tuition fees up to date                         4181 non-null   object \n",
      " 17  Gender                                          4181 non-null   object \n",
      " 18  Scholarship holder                              4181 non-null   object \n",
      " 19  Age at enrollment                               4181 non-null   float64\n",
      " 20  Curricular units 1st sem (evaluations)          4181 non-null   float64\n",
      " 21  Curricular units 1st sem (without evaluations)  4181 non-null   float64\n",
      " 22  Curricular units 1st sem (Approved/Enrolled)    4181 non-null   float64\n",
      " 23  Curricular units 2nd sem (evaluations)          4181 non-null   float64\n",
      " 24  Curricular units 2nd sem (without evaluations)  4181 non-null   float64\n",
      " 25  Curricular units 2nd sem (Approved/Enrolled)    4181 non-null   float64\n",
      " 26  Unemployment rate                               4181 non-null   float64\n",
      " 27  Inflation rate                                  4181 non-null   float64\n",
      " 28  GDP                                             4181 non-null   float64\n",
      " 29  Target                                          4181 non-null   object \n",
      "dtypes: float64(10), object(20)\n",
      "memory usage: 980.1+ KB\n",
      "None\n",
      "\n",
      "ğŸ’¾ Fichier final bien enregistrÃ© dans : c:\\Users\\romua\\Documents\\La_Plateforme_\\Projet 5 - Perceptron Multicouche\\ANN-playground\\data\\data_final.csv\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‹ # SUPPRESSION DES FEATURES CORRELLES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Suppression des features corrÃ©lÃ©es\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# DÃ©finir le chemin du dossier et du fichier\n",
    "data_folder = Path.cwd().parent / 'data'\n",
    "\n",
    "# _________________ 1ï¸âƒ£5ï¸âƒ£  SUPPRESSION DES FEATURES CORELLES _______________________\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ğŸ—‘ï¸ SUPPRESSION DES FEATURES CORELLES...\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Recharger le fichier CSV modifiÃ©\n",
    "file_path = data_folder / \"data_update.csv\"\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Colonnes Ã  supprimer en raison de la corrÃ©lation Ã©levÃ©e\n",
    "columns_to_drop_correlees = [\n",
    "    'Curricular units 2nd sem (credited)',\n",
    "    'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (credited)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'International'\n",
    "]\n",
    "\n",
    "# Suppression des colonnes\n",
    "df = df.drop(columns=columns_to_drop_correlees)\n",
    "print(f\"\\nColonnes supprimÃ©es en raison de la corrÃ©lation Ã©levÃ©e : {columns_to_drop_correlees}\")\n",
    "\n",
    "# Convertir les colonnes en type str \n",
    "columns_to_str=[\n",
    "    'Marital Status',\n",
    "    'Application mode',\n",
    "    'Application order',\n",
    "    'Course',\n",
    "    'Daytime/evening attendance',\n",
    "    'Previous qualification Group',\n",
    "    'Previous qualification (grade)',\n",
    "    'Nationality Group',\n",
    "    \"Mother's qualification Group\",\n",
    "    \"Father's qualification Group\",\n",
    "    \"Mother's occupation Group\",\n",
    "    \"Father's occupation Group\",\n",
    "    'Admission grade',\n",
    "    'Displaced',\n",
    "    'Educational special needs',\n",
    "    'Debtor',\n",
    "    'Tuition fees up to date',\n",
    "    'Gender',\n",
    "    'Scholarship holder',\n",
    "    'Target'\n",
    "]\n",
    "\n",
    "for col in columns_to_str:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "\n",
    "# Afficher le nombre de colonnes restantes\n",
    "print(f\"\\nNombre de colonnes restantes aprÃ¨s suppression : {df.shape[1]}\")\n",
    "\n",
    "# Afficher les informations sur le DataFrame aprÃ¨s suppression des colonnes corrÃ©lÃ©es\n",
    "print(\"\\nğŸ–¼ï¸ Information sur le DataFrame aprÃ¨s suppression des colonnes corrÃ©lÃ©es :\")\n",
    "print(df.info())\n",
    "\n",
    "# Sauvegarder le DataFrame aprÃ¨s suppression des colonnes corrÃ©lÃ©es\n",
    "file_path = data_folder / \"data_final.csv\"\n",
    "df.to_csv(file_path, sep=';', index=False, encoding='utf-8')\n",
    "print(f\"\\nğŸ’¾ Fichier final bien enregistrÃ© dans : {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a21a5303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chargement des donnÃ©es pour sÃ©paration...\n",
      "\n",
      "SÃ©paration du dataset en 2 fichiers...\n",
      "\n",
      "âœ… data_enrolled.csv\n",
      "  Nombre d'observations: 745\n",
      "  Nombre de colonnes: 30\n",
      "\n",
      "âœ… data_graduate_dropout.csv\n",
      "  Nombre d'observations: 3436\n",
      "  Nombre de colonnes: 30\n",
      "\n",
      "ğŸ¯ RÃ©partition des cibles dans data_graduate_dropout.csv :\n",
      "Target\n",
      "1    2097\n",
      "0    1339\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Pourcentages:\n",
      "Target\n",
      "1    61.0\n",
      "0    39.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‹ # SEPARATION DES DONNEES : TARGET(ENROLLED/GRADUATED/DROPOUT)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: SÃ©paration du dataset en deux fichiers distincts sÃ©parant ENROLLED et GRADUATED/DROPOUT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# _________________ 1ï¸âƒ£  CHARGEMENT DES DONNÃ‰ES _______________________\n",
    "# Recharger le fichier CSV pour s'assurer de partir d'une version propre\n",
    "\n",
    "print(\"\\nChargement des donnÃ©es pour sÃ©paration...\")\n",
    "\n",
    "# DÃ©finir le chemin du dossier et du fichier\n",
    "data_folder = Path.cwd().parent / 'data'\n",
    "\n",
    "# Charger les donnÃ©es\n",
    "df = pd.read_csv(data_folder / 'data_final.csv', delimiter=';')\n",
    "\n",
    "# _________________ 2ï¸âƒ£  CREER 2 FICHIERS SEPARÃ‰S _______________________\n",
    "# SÃ©paration du dataset en deux fichiers distincts\n",
    "\n",
    "print(\"\\nSÃ©paration du dataset en 2 fichiers...\")\n",
    "\n",
    "# FICHIER 1: Enrolled uniquement\n",
    "df_enrolled = df[df['Target'] == 2]\n",
    "df_enrolled.to_csv(data_folder / 'data_enrolled.csv', index=False, sep=';')\n",
    "\n",
    "print(f\"\\nâœ… data_enrolled.csv\")\n",
    "print(f\"  Nombre d'observations: {len(df_enrolled)}\")\n",
    "print(f\"  Nombre de colonnes: {len(df_enrolled.columns)}\")\n",
    "\n",
    "# FICHIER 2: Graduate + Dropout\n",
    "df_at_risk = df[df['Target'].isin([0, 1])]\n",
    "df_at_risk.to_csv(data_folder / 'data_graduate_dropout.csv', index=False, sep=';')\n",
    "\n",
    "print(f\"\\nâœ… data_graduate_dropout.csv\")\n",
    "print(f\"  Nombre d'observations: {len(df_at_risk)}\")\n",
    "print(f\"  Nombre de colonnes: {len(df_at_risk.columns)}\")\n",
    "\n",
    "# AFFICHER LES REPARTITIONS DES TARGETS DANS LE FICHIER GRADUATE/DROPOUT\n",
    "print(\"\\nğŸ¯ RÃ©partition des cibles dans data_graduate_dropout.csv :\")\n",
    "print(df_at_risk['Target'].value_counts())\n",
    "print(\"\\nPourcentages:\")\n",
    "print((df_at_risk['Target'].value_counts(normalize=True) * 100).round(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f46866eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SEPARATION DES DATASETS EN TRAIN ET TEST\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Informations sur les datasets train et test :\n",
      "- Nombre d'observations dans le dataset train: 2748\n",
      "- Nombre d'observations dans le dataset test: 688\n",
      "\n",
      "ğŸ¯ RÃ©partition des cibles dans le dataset train :\n",
      "Target\n",
      "1    1677\n",
      "0    1071\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Pourcentages:\n",
      "Target\n",
      "1    61.0\n",
      "0    39.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "ğŸ¯ RÃ©partition des cibles dans le dataset test :\n",
      "Target\n",
      "1    420\n",
      "0    268\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Pourcentages:\n",
      "Target\n",
      "1    61.0\n",
      "0    39.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "ğŸ’¾ Fichiers modifiÃ©s bien enregistrÃ©s dans : c:\\Users\\romua\\Documents\\La_Plateforme_\\Projet 5 - Perceptron Multicouche\\ANN-playground\\data\\data_train.csv et c:\\Users\\romua\\Documents\\La_Plateforme_\\Projet 5 - Perceptron Multicouche\\ANN-playground\\data\\data_test.csv\n"
     ]
    }
   ],
   "source": [
    "# âœ‚ï¸ # SEPARATION DES DONNEES : TRAIN / TEST\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: SÃ©paration du dataset en ensembles d'entraÃ®nement et de test pour les analyses prÃ©dictives futures.\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SEPARATION DES DATASETS EN TRAIN ET TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# _________________ 1ï¸âƒ£  CHARGEMENT DES DONNÃ‰ES _______________________\n",
    "\n",
    "# DÃ©finir le chemin du dossier et du fichier\n",
    "data_folder = Path.cwd().parent / 'data'\n",
    "\n",
    "# Recharger le fichier CSV pour s'assurer de partir d'une version propre\n",
    "df = pd.read_csv(data_folder / 'data_graduate_dropout.csv', delimiter=';')\n",
    "\n",
    "# _________________ 2ï¸âƒ£  SÃ‰PARATION TRAIN / TEST _______________________\n",
    "# SÃ©paration des donnÃ©es en ensembles d'entraÃ®nement et de test avec stratification\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# _________________ 3ï¸âƒ£  AFFICHAGE DES INFORMATIONS _______________________\n",
    "# Affichage des informations sur les datasets train et test\n",
    "print(\"\\nğŸ“Š Informations sur les datasets train et test :\")\n",
    "print(f\"- Nombre d'observations dans le dataset train: {len(X_train)}\")\n",
    "print(f\"- Nombre d'observations dans le dataset test: {len(X_test)}\")\n",
    "\n",
    "print(\"\\nğŸ¯ RÃ©partition des cibles dans le dataset train :\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nPourcentages:\")\n",
    "print((y_train.value_counts(normalize=True) * 100).round(1))\n",
    "\n",
    "print(\"\\nğŸ¯ RÃ©partition des cibles dans le dataset test :\")\n",
    "print(y_test.value_counts())\n",
    "print(\"\\nPourcentages:\")\n",
    "print((y_test.value_counts(normalize=True) * 100).round(1))\n",
    "\n",
    "# _________________ 4ï¸âƒ£  ENREGISTREMENT DES DATASETS _______________________\n",
    "# DÃ©finir le chemin du dossier et du fichier\n",
    "train_file_path = data_folder / \"data_train.csv\"\n",
    "test_file_path = data_folder / \"data_test.csv\"\n",
    "\n",
    "# Combiner les features et la target pour les datasets train et test\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Enregistrement des datasets train et test\n",
    "train_data.to_csv(train_file_path, index=False, sep=';',encoding='utf-8')\n",
    "test_data.to_csv(test_file_path, index=False, sep=';',encoding='utf-8')\n",
    "\n",
    "print(f\"\\nğŸ’¾ Fichiers modifiÃ©s bien enregistrÃ©s dans : {train_file_path} et {test_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c00394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENCODAGE DES DONNÃ‰ES CATEGORIELLES...\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Informations sur les datasets encodÃ©s :\n",
      "Train: 2748 observations, 74 features\n",
      "Test: 688 observations, 74 features\n",
      "\n",
      "ğŸ’¾ Fichiers modifiÃ©s bien enregistrÃ©s dans : c:\\Users\\romua\\Documents\\La_Plateforme_\\Projet 5 - Perceptron Multicouche\\ANN-playground\\data\\data_train_encoded.csv et c:\\Users\\romua\\Documents\\La_Plateforme_\\Projet 5 - Perceptron Multicouche\\ANN-playground\\data\\data_test_encoded.csv\n"
     ]
    }
   ],
   "source": [
    "# ğŸ‘¨â€ğŸ’» ENCODAGE DES DATASETS TRAIN/TEST\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Description: Encodage des variables catÃ©gorielles\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# _________________ 1ï¸âƒ£  CHARGEMENT DES DONNÃ‰ES _______________________\n",
    "# DÃ©finir le chemin du dossier et du fichier\n",
    "data_folder = Path.cwd().parent / 'data'\n",
    "\n",
    "# Charger les donnÃ©es\n",
    "df_train = pd.read_csv(data_folder / 'data_train.csv', delimiter=';')\n",
    "df_test = pd.read_csv(data_folder / 'data_test.csv', delimiter=';')\n",
    "\n",
    "# _________________ 2ï¸âƒ£  DÃ‰FINITION DES COLONNES CATEGORIELLES _______________________\n",
    "# colonnes catÃ©gorielles Ã  encoder\n",
    "colonne_features_categorielles = [\n",
    "    \"Marital Status\", \"Application mode\", \"Course\", \n",
    "    \"Daytime/evening attendance\", \"Displaced\", \n",
    "    \"Educational special needs\", \"Debtor\", \n",
    "    \"Tuition fees up to date\", \"Gender\", \n",
    "    \"Scholarship holder\"\n",
    "]\n",
    "\n",
    "# _________________ 3ï¸âƒ£  ENCODAGE DES DONNEES CATEGORIELLES _______________________\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENCODAGE DES DONNÃ‰ES CATEGORIELLES...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Garder l'ordre original des colonnes\n",
    "ordre_original = df_train.columns.tolist()\n",
    "\n",
    "# CrÃ©er des copies des DataFrames pour le traitement\n",
    "df_train_processed = df_train.copy()\n",
    "df_test_processed = df_test.copy()\n",
    "\n",
    "# Traiter chaque colonne catÃ©gorielles, une par une\n",
    "for col in colonne_features_categorielles:\n",
    "        \n",
    "    # CrÃ©er l'encodeur et l'entraÃ®ner sur le TRAIN\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoder.fit(df_train[[col]])\n",
    "    \n",
    "    # Encoder le TRAIN et le TEST\n",
    "    X_train_encoded = encoder.transform(df_train[[col]])\n",
    "    X_test_encoded = encoder.transform(df_test[[col]])\n",
    "    \n",
    "    # Noms des colonnes encodÃ©es\n",
    "    feature_names = encoder.get_feature_names_out([col])\n",
    "\n",
    "    # CrÃ©er les DataFrames avec les colonnes encodÃ©es\n",
    "    df_train_encoded_col = pd.DataFrame(X_train_encoded, columns=feature_names, index=df_train.index)\n",
    "    df_test_encoded_col = pd.DataFrame(X_test_encoded, columns=feature_names, index=df_test.index)\n",
    "    \n",
    "    # Trouver la position de la colonne originale\n",
    "    col_position = df_train_processed.columns.get_loc(col)\n",
    "    \n",
    "    # Supprimer la colonne originale\n",
    "    df_train_processed = df_train_processed.drop(columns=[col])\n",
    "    df_test_processed = df_test_processed.drop(columns=[col])\n",
    "    \n",
    "    # InsÃ©rer les colonnes encodÃ©es Ã  la bonne position\n",
    "    for i, feat_name in enumerate(feature_names):\n",
    "        df_train_processed.insert(col_position + i, feat_name, df_train_encoded_col[feat_name])\n",
    "        df_test_processed.insert(col_position + i, feat_name, df_test_encoded_col[feat_name])\n",
    "\n",
    "\n",
    "# _________________ 4ï¸âƒ£  AFFICHAGE DES INFORMATIONS _______________________\n",
    "# Affichage des informations sur les datasets encodÃ©s\n",
    "print(f\"\\nğŸ“Š Informations sur les datasets encodÃ©s :\")\n",
    "print(f\"Train: {df_train_processed.shape[0]} observations, {df_train_processed.shape[1]} features\")\n",
    "print(f\"Test: {df_test_processed.shape[0]} observations, {df_test_processed.shape[1]} features\")\n",
    "\n",
    "# _________________ 5ï¸âƒ£  ENREGISTREMENT DES DATASETS _______________________\n",
    "# Enregistrement des datasets encodÃ©s\n",
    "df_train_processed.to_csv(data_folder / 'data_train_encoded.csv', index=False, sep=';')\n",
    "df_test_processed.to_csv(data_folder / 'data_test_encoded.csv', index=False, sep=';')\n",
    "\n",
    "print(f\"\\nğŸ’¾ Fichiers modifiÃ©s bien enregistrÃ©s dans : {data_folder / 'data_train_encoded.csv'} et {data_folder / 'data_test_encoded.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
